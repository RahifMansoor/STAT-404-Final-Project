knitr::opts_chunk$set(
echo = TRUE,
warning = FALSE,
message = FALSE,
fig.width = 10,
fig.height = 6
)
# Load required packages
library(ggplot2)
library(gridExtra)
# Source our functions
source("R/core_functions.R")
source("R/visualization_functions.R")
# Compare different sample sizes
plot_sampling_dist(
n_values = c(10, 30, 50, 100),  # varying sample sizes
p1 = 0.7,                       # probability for group 1
p2 = 0.5,                       # probability for group 2
reps = 1000                     # number of simulations
)
# Look at coverage probability for 95% confidence intervals
plot_confidence_coverage(
p1 = 0.7,           # probability for group 1
p2 = 0.5,           # probability for group 2
n1 = 50,            # sample size group 1
n2 = 50,            # sample size group 2
alpha = 0.05,       # 95% confidence level
max_reps = 500      # maximum number of repetitions
)
# Look at coverage probability for 95% confidence intervals
plot_confidence_coverage(
p1 = 0.7,           # probability for group 1
p2 = 0.5,           # probability for group 2
n1 = 50,            # sample size group 1
n2 = 50,            # sample size group 2
alpha = 0.05,       # 95% confidence level
max_reps = 500      # maximum number of repetitions
)
# Look at coverage probability for 95% confidence intervals
plot_confidence_coverage(
p1 = 0.7,           # probability for group 1
p2 = 0.5,           # probability for group 2
n1 = 50,            # sample size group 1
n2 = 50,            # sample size group 2
alpha = 0.05,       # 95% confidence level
max_reps = 500      # maximum number of repetitions
)
# Look at coverage probability for 95% confidence intervals
plot_confidence_coverage(
p1 = 0.7,           # probability for group 1
p2 = 0.5,           # probability for group 2
n1 = 50,            # sample size group 1
n2 = 50,            # sample size group 2
alpha = 0.05,       # 95% confidence level
max_reps = 500      # maximum number of repetitions
)
knitr::opts_chunk$set(
echo = TRUE,
warning = FALSE,
message = FALSE,
fig.width = 10,
fig.height = 6
)
# Load required packages
library(ggplot2)
library(gridExtra)
# Source our functions
source("R/core_functions.R")
source("R/visualization_functions.R")
# Compare different sample sizes
plot_sampling_dist(
n_values = c(10, 30, 50, 100),  # varying sample sizes
p1 = 0.7,                       # probability for group 1
p2 = 0.5,                       # probability for group 2
reps = 1000                     # number of simulations
)
# Look at coverage probability for 95% confidence intervals
plot_confidence_coverage(
p1 = 0.7,           # probability for group 1
p2 = 0.5,           # probability for group 2
n1 = 50,            # sample size group 1
n2 = 50,            # sample size group 2
alpha = 0.05,       # 95% confidence level
max_reps = 500      # maximum number of repetitions
)
# Generate data with a known difference
set.seed(123)  # for reproducibility
data <- sim_binary_data(0.7, 0.5, 50, 50)
# Perform and visualize permutation test
plot_permutation_test(data, reps = 1000)
# Compare bootstrap and theoretical approaches
plot_bootstrap_comparison(data, reps = 1000, conf_level = 0.95)
# Set parameters
p1 <- 0.7  # probability for group 1
p2 <- 0.5  # probability for group 2
n <- 50    # sample size per group
reps <- 1000  # number of repetitions
# 1. Generate data
set.seed(456)  # for reproducibility
data <- sim_binary_data(p1, p2, n, n)
# 2. Calculate observed difference and SE
results <- calc_prop_diff(data)
cat("Observed difference:", round(results$diff, 3), "\n")
cat("Standard error:", round(results$se, 3), "\n")
# 3. Perform permutation test
perm_results <- permutation_test(data, reps)
p_value <- mean(abs(perm_results$null_dist) >= abs(perm_results$obs_stat))
cat("Permutation test p-value:", round(p_value, 3), "\n")
# 4. Calculate bootstrap confidence interval
boot_samples <- bootstrap_samples(data, reps)
boot_ci <- quantile(boot_samples, c(0.025, 0.975))
cat("Bootstrap 95% CI: (", round(boot_ci[1], 3), ",", round(boot_ci[2], 3), ")\n")
# Visualize all aspects
par(mfrow = c(2,2))
# Sampling distribution
plot_sampling_dist(c(n), p1, p2, reps)
# Confidence coverage
plot_confidence_coverage(p1, p2, n, n, max_reps = reps)
# Permutation test
plot_permutation_test(data, reps)
# Bootstrap comparison
plot_bootstrap_comparison(data, reps)
# Compare cases with unequal sample sizes
data_unequal <- sim_binary_data(0.7, 0.5, 30, 70)
plot_permutation_test(data_unequal, reps = 1000)
# Small effect
data_small <- sim_binary_data(0.52, 0.50, 50, 50)
plot_permutation_test(data_small, reps = 1000)
# Large effect
data_large <- sim_binary_data(0.8, 0.4, 50, 50)
plot_permutation_test(data_large, reps = 1000)
# Function to calculate power
calc_power <- function(p1, p2, n, reps = 1000, alpha = 0.05) {
results <- replicate(reps, {
data <- sim_binary_data(p1, p2, n, n)
perm_results <- permutation_test(data, 100)
p_value <- mean(abs(perm_results$null_dist) >= abs(perm_results$obs_stat))
p_value <= alpha
})
mean(results)
}
# Calculate power for different sample sizes
n_seq <- seq(20, 100, by = 20)
power_results <- sapply(n_seq, function(n) calc_power(0.7, 0.5, n))
# Plot power curve
ggplot(data.frame(n = n_seq, power = power_results), aes(x = n, y = power)) +
geom_line() +
geom_point() +
geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
labs(x = "Sample Size per Group",
y = "Power",
title = "Power Analysis for Detecting Difference between p1 = 0.7 and p2 = 0.5") +
theme_minimal()
knitr::opts_chunk$set(
echo = TRUE,
warning = FALSE,
message = FALSE,
fig.width = 10,
fig.height = 6
)
# Load required packages
library(ggplot2)
library(gridExtra)
# Source our functions
source("R/core_functions.R")
source("R/visualization_functions.R")
# Compare different sample sizes
plot_sampling_dist(
n_values = c(10, 30, 50, 100),  # varying sample sizes
p1 = 0.7,                       # probability for group 1
p2 = 0.5,                       # probability for group 2
reps = 1000                     # number of simulations
)
# Look at coverage probability for 95% confidence intervals
plot_confidence_coverage(
p1 = 0.7,           # probability for group 1
p2 = 0.5,           # probability for group 2
n1 = 50,            # sample size group 1
n2 = 50,            # sample size group 2
alpha = 0.05,       # 95% confidence level
max_reps = 500      # maximum number of repetitions
)
# Generate data with a known difference
set.seed(123)  # for reproducibility
data <- sim_binary_data(0.7, 0.5, 50, 50)
# Perform and visualize permutation test
plot_permutation_test(data, reps = 1000)
# Compare bootstrap and theoretical approaches
plot_bootstrap_comparison(data, reps = 1000, conf_level = 0.95)
# Set parameters
p1 <- 0.7  # probability for group 1
p2 <- 0.5  # probability for group 2
n <- 50    # sample size per group
reps <- 1000  # number of repetitions
# 1. Generate data
set.seed(456)  # for reproducibility
data <- sim_binary_data(p1, p2, n, n)
# 2. Calculate observed difference and SE
results <- calc_prop_diff(data)
cat("Observed difference:", round(results$diff, 3), "\n")
cat("Standard error:", round(results$se, 3), "\n")
# 3. Perform permutation test
perm_results <- permutation_test(data, reps)
p_value <- mean(abs(perm_results$null_dist) >= abs(perm_results$obs_stat))
cat("Permutation test p-value:", round(p_value, 3), "\n")
# 4. Calculate bootstrap confidence interval
boot_samples <- bootstrap_samples(data, reps)
boot_ci <- quantile(boot_samples, c(0.025, 0.975))
cat("Bootstrap 95% CI: (", round(boot_ci[1], 3), ",", round(boot_ci[2], 3), ")\n")
# Visualize all aspects
par(mfrow = c(2,2))
# Sampling distribution
plot_sampling_dist(c(n), p1, p2, reps)
# Confidence coverage
plot_confidence_coverage(p1, p2, n, n, max_reps = reps)
# Permutation test
plot_permutation_test(data, reps)
# Bootstrap comparison
plot_bootstrap_comparison(data, reps)
# Compare cases with unequal sample sizes
data_unequal <- sim_binary_data(0.7, 0.5, 30, 70)
plot_permutation_test(data_unequal, reps = 1000)
# Small effect
data_small <- sim_binary_data(0.52, 0.50, 50, 50)
plot_permutation_test(data_small, reps = 1000)
# Large effect
data_large <- sim_binary_data(0.8, 0.4, 50, 50)
plot_permutation_test(data_large, reps = 1000)
# Function to calculate power
calc_power <- function(p1, p2, n, reps = 1000, alpha = 0.05) {
results <- replicate(reps, {
data <- sim_binary_data(p1, p2, n, n)
perm_results <- permutation_test(data, 100)
p_value <- mean(abs(perm_results$null_dist) >= abs(perm_results$obs_stat))
p_value <= alpha
})
mean(results)
}
# Calculate power for different sample sizes
n_seq <- seq(20, 100, by = 20)
power_results <- sapply(n_seq, function(n) calc_power(0.7, 0.5, n))
# Plot power curve
ggplot(data.frame(n = n_seq, power = power_results), aes(x = n, y = power)) +
geom_line() +
geom_point() +
geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
labs(x = "Sample Size per Group",
y = "Power",
title = "Power Analysis for Detecting Difference between p1 = 0.7 and p2 = 0.5") +
theme_minimal()
